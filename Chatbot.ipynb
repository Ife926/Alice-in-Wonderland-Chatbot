{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcBOfRM3cN6LLQyUfZxF/V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristabelJohnny/Alice-in-Wonderland-Chatbot/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to Chatbots**\n",
        "**A. What are Chatbots ?**\n",
        "\n",
        "Chatbots are conversational programs that automate interactions. They are artificial intelligence (AI) softwares designed to simulate conversation with human users, typically through text or voice.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "- A chatbot on a bank's website that helps with enquiries\n",
        "- A chatbot on an e-commerce site that tracks orders or provides recommendations\n",
        "- Virtual assistants like Siri and Alexa\n",
        "\n",
        "**B. Difference Between Chatbots and Bots**\n",
        "\n",
        "**Chatbots** are a subset of bots. They are specifically designed for conversation, meaning they are programmed to interact using natural language processing (NLP) to simulate human conversations.\n",
        "\n",
        "**Bots**, on the other hand are more general-purpose programs designed to aautomate tasks. They dont necessarily interact, but they perform specific functions like web scraping, sending reminders or managing social media posts.\n",
        "\n",
        "- Chatbot: Focuses on conversation(e.g., answering customer queries).\n",
        "- Bot: Focuses on automating repetitive tasks(e.g;, posting scheduled tweets).\n",
        "\n",
        "**C. Types of chatbots**\n",
        "\n",
        "**1. Rule-Based Chatbots:**\n",
        "\n",
        "They follow specific set of instructions or rules. It works by looking for specific keywords or patterns in what you say and then picking the correct response from its list.\n",
        "The problem is if you ask something it wasnt programmed for, it might get confused or give a response that doesnt make sense.\n",
        "\n",
        "**2. Retrieval-Based Chatbots**\n",
        "\n",
        "They are a bit smarter tha rule-based ones. Instead of giving a fixed reply, they search through a bunch of pre-written response and try to find the best one based on what you said. Its like going through a library to find the book that most closely answers your question.\n",
        "\n",
        "**Techniques Used**:\n",
        "- **Jaccard similarity:** Imagine you ask a question like, \"What's the weather today?\" The bot checks which of its stored answers have the most words in comnmon with your question. The more words they share, the more likely it is to pick that answer.\n",
        "- **Cosine Similarity:** This is like comparing two texts using math. It turns your words into numbers and checks how similar they are. If the numbers line up, the bot figures that the answer might be a good fit.\n",
        "- **Machine Learning Models like 'Naive Bayes':** This is where the bot starts to guess what you're talking about, learning from the past examples. If its trained to answer questions about sports, it'll know that when you ask about \"Football\", it should probably give a sport related response.\n",
        "\n",
        "**3. Generative Chatbot:**\n",
        "- They are the most advanced chatbots. Instead of pulling from a list of pre-written answers, they create their own responses based on what you said. it's like having a conversation with someone who thinks on the spot and makes up their answers.\n",
        "- However, they need a lot of training to get good at answering questions. They use models like RNNs, LSTMs."
      ],
      "metadata": {
        "id": "pCYuToho9ZsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **An example illustrating rule-based, retrieval-based, and generative chatbots using a simple customer service scenario related to order tracking.**\n",
        "\n",
        "**Scenario**\n",
        "\n",
        "This user asks: **\"Where is my order?\"**\n",
        "\n",
        "**1. Rule-Based Chatbot Example:**\n",
        "- In a rule-based chatbot, predefined keywords like \"order\" and \"track\" to trigger specific responses.\n",
        "\n"
      ],
      "metadata": {
        "id": "yLF7xlRMJvvk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyl6k1nR8tyM",
        "outputId": "d5bd243a-bf02-410d-a1d8-273b5f728e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How may i help you?\n",
            "I need a refund\n",
            "For a refund, please visit our refund policy page.\n"
          ]
        }
      ],
      "source": [
        "# Define a function for a simple rule-based chatbot\n",
        "def rule_based_chatbot(user_input):\n",
        "  # Check if the user input contain the words \"track\" or \"order\"\n",
        "  if \"track\" in user_input.lower() or \"order\" in user_input.lower():\n",
        "    # Respond with a prompt to provide an order number\n",
        "    return \"Please provide your order number to track your order.\"\n",
        "\n",
        "  elif \"refund\" in user_input.lower():\n",
        "    # Respond with information about the refund policy\n",
        "    return \"For a refund, please visit our refund policy page.\"\n",
        "\n",
        "\n",
        "  # If the input doesn't match any of the predefined rules\n",
        "  else:\n",
        "      # Respond with a message indicating the chatbot doesn't understand the query\n",
        "      return \"I'm sorry, I didn't understand that. Can you try again?\"\n",
        "\n",
        "\n",
        "# Example user input\n",
        "user_query = input(\"How may i help you?\\n\")\n",
        "\n",
        "print(rule_based_chatbot(user_query))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Retrieval-Based Chatbot Example (Jaccard Similarity):**\n",
        "- In a retrieval-based chatbot, the bot looks for similar sentences in a predefined set of responses"
      ],
      "metadata": {
        "id": "y0V9kShZPutK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlJ0QL_AFA6s",
        "outputId": "9ef5bb96-47df-4fa5-ccb3-41cf25be725f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrqJWiL6FNXC",
        "outputId": "3a7633d7-0a85-4f57-9f3f-db61952002cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "# A predefined set of possible responses for the chatbot stored as a list\n",
        "responses = [\n",
        "    \"Please provide your order number to track your order\",\n",
        "    \"For a refund, please visit our refund policy page.\",\n",
        "    \"Our customer service is available 24/7\"\n",
        "]\n",
        "\n",
        "# Load a set of English stopwords (common words that may be removed in text preprocessing)\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Define preprocess function to clean and prepare text data\n",
        "def preprocess(text):\n",
        "  # Tokenize the input text into individual words and convert them to lowercase\n",
        "  words = word_tokenize(text.lower())\n",
        "\n",
        "  # Remove stopwords (e.g \"the\", \"is\") and punctuations\n",
        "  words = [word for word in words if word not in stop_words and word not in string.punctuation]\n",
        "\n",
        "  # Return the cleaned list of words\n",
        "  return words\n",
        "\n",
        "\n",
        "\n",
        "# Define function to calculate jaccard similarity between two sentences\n",
        "def jaccard_similarity(query, sentence):\n",
        "  # Preprocess the query and the sentence\n",
        "  query_set = set(preprocess(query))\n",
        "  sentence_set = set(preprocess(sentence))\n",
        "\n",
        "  # Calculate the intersection and union of the sets and return jaccord similarity score\n",
        "  return len(query_set.intersection(sentence_set)) / len(query_set.union(sentence_set))\n",
        "\n",
        "\n",
        "# Define function to find the most relevant response based on user input\n",
        "def retrieval_based_chatbot(user_input):\n",
        "  best_response = \"\"  # Placeholder for the best matching response\n",
        "  highest_similarity = 0\n",
        "\n",
        "# Loop through each predefined response and calculate the jaccard similarity\n",
        "  for response in responses:\n",
        "    similarity = jaccard_similarity(user_input, response)\n",
        "\n",
        "  # Update the best response if the current response has a higher similarity score\n",
        "    if similarity > highest_similarity:\n",
        "      highest_similarity = similarity\n",
        "      best_response = response\n",
        "\n",
        "  # Return the best response\n",
        "  return best_response if best_response else \"I'm sorry, I couldn't find a relevant response.\"\n",
        "\n",
        "\n",
        "# User Input\n",
        "user_query = input(\"How may i help you? \\n\")\n",
        "\n",
        "print(retrieval_based_chatbot(user_query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaW-zumZOug9",
        "outputId": "c38f2999-1b0f-41ea-c664-b52d67876ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How may i help you? \n",
            "where is my order?\n",
            "Please provide your order number to track your order\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Generative Chatbot**\n",
        "In a generative chatbot, the response is generated dynamically using a machine learning model (like GPT). This would involve training a deep learning model.\n",
        "\n",
        "- **How it works:** The generative chatbot creates a new response based on the user input, generating an original sentence that wasn't pre-programmed or retrieve a predefined list.\n"
      ],
      "metadata": {
        "id": "fr8kdWpNAIW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **D. Common Terms in Natural Language Processing (NLP)**\n",
        "\n",
        "# 1. **Natural Language Processing(NLP)**\n",
        "NLP is a way for computers to understand, interpret, and respond to human language. With NLP, computers can read, listen, and even reply like humans.\n",
        "\n",
        "# 2. **Tokenization**\n",
        "Tokenization is breaking down a sentence into similar pieces that a computer can understand.\n",
        "\n",
        "# 3. **Lemmatization**\n",
        "Lemmatization is when the computer changes word to their simplest form, called the **Lemma**. For example, the word \"running\" changes to \"run\".\n",
        "\n",
        "# 4. **Stemming**\n",
        "Stemming is when the computer cuts off the end of words to get the base form, or **Stem**. For example, \"Playing\", \"Played\", and \"Plays\" all becomes \"Play\". This is different from lemmatization because it chops off word endings. Stemming helps computers group words with similar meanings together by chopping off the extra ending.\n",
        "\n",
        "# 5. **Stopwords**\n",
        "Stopwords are very common words, like \"the\", \"is\", \"and\", \"in\" that computers often ignore when analyzing a sentence.\n",
        "\n",
        "# 6. **Corpus**\n",
        "A **Corpus** is a large collection of written or spoken text that computers use to learn and analyze language. It's like giving the computer lots of books to read and study from.\n",
        "\n",
        "# 7. **Bag of Words(BOW)**\n",
        "Is a simple way for computers to represent text. It works by counting how many times each word appears in a text, without caring about the order of the words.\n",
        "\n",
        "#8. **TF-IDF (Term Frequency-Inverse Document Frequency)**\n",
        "TF-IDF is a more advanced version of **Bag of Words**. It doesn't just count how often a word appears in a text (like BOW), it also checks how rare or important that word is across many documents.\n"
      ],
      "metadata": {
        "id": "jXt6BkefCmHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **E. Workflow for Building a Simple Chatbot using NLTK(Natural Language Toolkit)**"
      ],
      "metadata": {
        "id": "aa9vD8rkQMqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install NLTK and Download all necessary resources.\n",
        "# !pip install nltk\n",
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('punkt_tab')\n",
        "\n",
        "# Alternatively\n",
        "# nltk.download()"
      ],
      "metadata": {
        "id": "eRUskIunEVob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the Data**"
      ],
      "metadata": {
        "id": "uATZqHP2SkZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the alice_in_wonderland.txt file\n",
        "\n",
        "with open(\"alice_in_wonderland.txt\",\"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read().replace(\"\\n\", \" \")"
      ],
      "metadata": {
        "id": "4hNWdNsxSCw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocess the Data**"
      ],
      "metadata": {
        "id": "3q9o50unTz3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "\n",
        "\n",
        "# Initialize stopwords and Lemmatizer\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "# Use a function for preprocessing each sentence\n",
        "def preprocess(sentence):\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "\n",
        "\n",
        "# Tokenize text into sentences\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "corpus = [preprocess(sentence) for sentence in sentences]"
      ],
      "metadata": {
        "id": "vrPwYd9nTZX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implement Jaccard Similarity for Response Matching**"
      ],
      "metadata": {
        "id": "S5QCC9nUZiBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to calculate jaccard similarity between two sentences\n",
        "def jaccard_similarity(query, sentence):\n",
        "  # Preprocess the query and the sentence\n",
        "  query_set = set(preprocess(query))\n",
        "  sentence_set = set((sentence))\n",
        "\n",
        "  # Calculate the intersection and union of the sets and return jaccord similarity score\n",
        "  return len(query_set.intersection(sentence_set)) / len(query_set.union(sentence_set))\n",
        "\n",
        "\n",
        "def get_response(query):\n",
        "    max_similarity = 0\n",
        "    best_response = \"\"\n",
        "    for i, sentence in enumerate(corpus):\n",
        "        similarity = jaccard_similarity(query, sentence)\n",
        "        if similarity > max_similarity:\n",
        "            max_similarity = similarity\n",
        "            best_response = sentences[i]\n",
        "    return best_response"
      ],
      "metadata": {
        "id": "4kUIYReyYqVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = input(\"What can i help you with? \\n\")\n",
        "response = get_response(user_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9wHSpvPi8X8",
        "outputId": "36fb3ac0-0ac1-430a-fb43-214f6f276e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What can i help you with? \n",
            "who did Alice first meet in wonderland?\n",
            "He had been looking at Alice for some time with great curiosity, and this was his first speech.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nWdtitDfjT6x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}